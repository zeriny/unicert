[{"id":0,"href":"/docs/posts/testing-for-tls-implementation/","title":"Testing of TLS Implementations","section":"Resources","content":"TLS Libarary Test ToolSource Code\nFix # The Go team has resolved the decoding issue; for details, see: golang/go#71862. Oracle has addressed the decoding issue, credited us in their Critical Patch Update (CPU), see https://www.oracle.com/security-alerts/cpuoct2025.html, and assigned CVE-2025-53057 for this vulnerability. CertificateGenerator and TestCertificates # We focus on the DN and GeneralName\u0026rsquo;s ASN1String (PrintableString Ia5String UTF8String BMPString) in Subject, Issuer, SAN, IAN, AIA, SIA, cRLDistributionPoints.\nFor DN, we only focus on these common OIDs: 2.5.4.3, 2.5.4.15, 0.9.2342.19200300.100.1.25, 1.2.840.113549.1.9.1, 2.5.4.7, 2.5.4.11, 2.5.4.10, 2.5.4.5, 2.5.4.8. We want to see how different OID+ASN1String combinations handle characters, so we combine different OIDs and ASN1Strings, and fill them with different characters including all characters from U+0000-U+00FF, plus sampled characters from the remaining Unicode range (randomly selecting one from each block in https://unicode.org/Public/15.0.0/ucd/Blocks.txt). Each certificate will only test one field.\nFor GeneralName, we only focus on dNSName, RFC822Name and URI - these relatively common types. The method for generating test certificates is similar to above.\nIn the CertificateGenerator, ASN.1 string types are encoded as follows: BMPString uses UTF-16-BE, while IA5String, PrintableString, and UTF8String use UTF-8. This is useful for decoding inference.\nThe complete test certificates and their corresponding parsing results need to be generated by CertificateGenerator/GenerateCerts.py and multiple parsers.\nFile Description # Block_unicode15.0.json is our processed file based on unicode15.0 Block.txt. Generator.py is a script for batch certificate generation convenience. GenerateCerts.py is the script for generating test certificates. SelectedChars.txt is the Unicode charset selected for our experiments. TestGeneration.py is an example of using Generator.py. When using CertificateGenerator/GenerateCerts.py to generate certificates, please use CryptoGraphy@V42.0.7. When prompted about illegal character embedding, please follow the prompt to comment out the corresponding check in CryptoGraphy.\nTest certificate description # sha1: The SHA-1 fingerprint of the certificate pem: The certificate in PEM format ​FocusField: The field being tested in the current certificate ​FocusFieldValue: The embedded value in the field ​InsertValue: Indicates the Unicode character being tested ​description: Descriptive information Note:We encountered an issue where the C JSON library (cJSON) fails to properly process strings containing embedded U+0000 characters, resulting in truncation of our inserted field values including U+0000. This directly impacts the normal functioning of our decoding detectors. To address this,we have excluded all test cases involving U+0000 embedding from automated processing and manually validate their results.\nCertificateParsers # Please note that since some libraries such as Golang Crypto have been modified accordingly, you can not obtain the same result.\nParsedCertifciates # Some fields from the input file are included in the output file. The Status field indicates whether the certificate was parsed successfully overall. The xxStatus field, present in some results, indicates whether a specific field was parsed successfully. Other JSON fields in the output correspond to the parsed values of the respective certificate fields. To understand the mapping between the called functions and JSON fields, refer to the parsers in CertificateParsers.\nEncodingDetection # EncodingDetection/src/main/java/TlsImplementationTest/Unicert/EncodingDetection.java extracts the DER byte sequences of subfields in Subject, Issuer, SAN, IAN, AIA, SIA, CRLDistributionPoints from certificates, identifies the Type-Length-Value (TLV) structure within the byte sequences, and verifies whether the Value conforms to the ASN.1 String type declared in Type. This program can detect certificates with ASN.1 string encoding errors.\nEncodingDetection/src/main/java/TlsImplementationTest/Unicert/CertificateBuilder.java further analyzes certificates with ASN.1 string encoding errors by performing certificate chain validation, including:\nWhether the last certificate in the chain is self-signed Whether the certificate chain signatures are valid The trustworthiness of the root certificate (measured by acceptance in mainstream root stores) The EncodingDetection/src/main/resources/ROOT directory contains all mainstream root stores we selected for evaluation.\nThe EncodingDetection/src/main/resources/CertsWithEncodingErrors.json contains all certificates with ASN1String encoding issues.\nThe EncodingDetection/src/main/resources/CertsWithEncodingErrors_check.json is the result of performing certificate chain analysis on CertsWithEncodingErrors.json.\nThe EncodingDetection/src/main/resources/CertsWithEncodingErrors_check_trusted.json includes all certificates with encoding issues that are signed by trusted CAs.\nThe EncodingDetection/src/main/resources/CertsWithEncodingErrors_check_trusted_SubjectSAN.json contains certificates from EncodingDetection/src/main/resources/CertsWithEncodingErrors_check_trusted.json that have encoding issues in their Subject or SAN fields.\nCertificateDecodingChecker # We observed that different TLS implementations have decoding errors and special character handling errors when parsing ASN1String. Subsequently, we developed corresponding decoding detectors for each parser.\nThe purpose of the decoding detectors are to infer the ASN1String decoding method and character handling modes used by TLS libraries.\nThe principle of the decoding detectors is described in our paper.\nOutput format of decoding detectors # For each field, the output of the decoding detector should be as follows:\nparsing_failed: The set of characters that cause parsing failure in the field or the entire certificate possible_decodings: The set of potential decoding methods for successfully parsed characters deduced_decoding: The unique decoding method derived from ​​possible_decodings​​ replacement: The set of characters that trigger character replacement escaping: The set of characters that trigger character escaping truncation: The set of characters that trigger character truncation possible_decodings_ex: The set of potential decoding methods for characters that undergo special handling deduced_decoding_ex: The unique decoding method derived from ​​possible_decodings_ex​​ deduced_decoding_include_ex: The unique decoding method derived from both ​​deduced_decoding_ex​​ and ​​deduced_decoding​​ possible_replacement: The set of characters that may trigger character replacement​ possible_escaping: The set of characters that may trigger character escaping possible_truncation: The set of characters that may trigger character truncation is_unidecoding: If ​​True​​, it indicates that (apart from unparsable characters) all other characters in the field follow a unified decoding method, which is ​​deduced_decoding_include_ex​​ We will mark ​​deduced_decoding​​ and ​​deduced_decoding_ex​​ as ​​\u0026quot;pass\u0026quot;​​, indicating that we do not process this field. When a field\u0026rsquo;s ​​is_unidecoding​​ is ​​True​ and parsing_failed is empty​, the field can be ​​fully automated​ except for parsing DN in OpenSSL and GN in java.security.cert(modified decoding interfere with the proper identification of character escaping)​. Otherwise, ​​manual inspection​​ is required.\nUsage of the decoding detectors\u0026rsquo; output # In the cases of R1 and R2, the results from decoding detectors are fully reliable, whereas in UR1, UR2, and UR3 scenarios, manual inspection is required. Most fields\u0026rsquo; corresponding results do not necessitate additional manual checks.\nR1: The output of decoding detectors is fully reliable.\n\u0026#34;Forge-Subject-2.5.4.3-UTF8String\u0026#34;: { \u0026#34;parsing_failed\u0026#34;: [], \u0026#34;possible_replacement\u0026#34;: [], \u0026#34;replacement\u0026#34;: [], \u0026#34;possible_escaping\u0026#34;: [], \u0026#34;escaping\u0026#34;: [], \u0026#34;possible_truncation\u0026#34;: [], \u0026#34;truncation\u0026#34;: [], \u0026#34;possible_decodings\u0026#34;: [ \u0026#34;iso-8859-1\u0026#34;, \u0026#34;ascii\u0026#34; ], \u0026#34;possible_decodings_ex\u0026#34;: [], \u0026#34;is_unidecoding\u0026#34;: true, \u0026#34;deduced_decoding\u0026#34;: \u0026#34;iso-8859-1\u0026#34;, \u0026#34;deduced_decoding_ex\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;deduced_decoding_include_ex\u0026#34;: \u0026#34;iso-8859-1\u0026#34; } Forge strictly adheres to ISO-8859-1 for decoding PrintableString in Subject 2.5.4.3 without any special character handling mode.\nR2: The output of decoding detectors is reliable, although not all embedded characters can be successfully decoded or match special character handling modes.\n\u0026#34;PyOpenSSL-Subject-2.5.4.3-BMPString\u0026#34;: { \u0026#34;parsing_failed\u0026#34;: [ \u0026#34;10069-108C79\u0026#34; ], \u0026#34;possible_replacement\u0026#34;: [], \u0026#34;replacement\u0026#34;: [], \u0026#34;possible_escaping\u0026#34;: [], \u0026#34;escaping\u0026#34;: [], \u0026#34;possible_truncation\u0026#34;: [], \u0026#34;truncation\u0026#34;: [], \u0026#34;possible_decodings\u0026#34;: [ \u0026#34;ucs-2\u0026#34; ], \u0026#34;possible_decodings_ex\u0026#34;: [], \u0026#34;is_unidecoding\u0026#34;: true, \u0026#34;deduced_decoding\u0026#34;: \u0026#34;ucs-2\u0026#34;, \u0026#34;deduced_decoding_ex\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;deduced_decoding_include_ex\u0026#34;: \u0026#34;ucs-2\u0026#34; } Although some characters lead to parse failure, these were inherently invalid for UCS-2. Therefore, PyOpenSSL strictly adheres to UCS-2 when decoding BMPString in Subject 2.5.4.3, applying no special character handling modes. When decoding detectors produce reliable output, replacement, escaping, and truncation can be employed for character checks.\nUR1: The presence of modified decoding compromises the reliability of decoding detectors\u0026rsquo; output.\n\u0026#34;OpenSSL-SubjectOneline-2.5.4.3-PrintableString\u0026#34;: { \u0026#34;parsing_failed\u0026#34;: [], \u0026#34;possible_replacement\u0026#34;: [], \u0026#34;replacement\u0026#34;: [], \u0026#34;possible_escaping\u0026#34;: [], \u0026#34;escaping\u0026#34;: [ \u0026#34;0001-001F\u0026#34;, \u0026#34;007F-108C79\u0026#34; ], \u0026#34;possible_truncation\u0026#34;: [], \u0026#34;truncation\u0026#34;: [], \u0026#34;possible_decodings\u0026#34;: [ \u0026#34;ascii\u0026#34; ], \u0026#34;possible_decodings_ex\u0026#34;: [ \u0026#34;ascii\u0026#34;, \u0026#34;utf-8\u0026#34; ], \u0026#34;is_unidecoding\u0026#34;: true, \u0026#34;deduced_decoding\u0026#34;: \u0026#34;ascii\u0026#34;, \u0026#34;deduced_decoding_ex\u0026#34;: \u0026#34;utf-8\u0026#34;, \u0026#34;deduced_decoding_include_ex\u0026#34;: \u0026#34;utf-8\u0026#34; } When \u0026lsquo;SubjeU+0209ct\u0026rsquo; undergoes UTF-8 encoding and subsequent decoding, it yields the same string \u0026lsquo;SubjeU+0209ct\u0026rsquo;. This was mistakenly interpreted as character escaping in relation to the parsed value \u0026lsquo;subje\\xC8\\x89ct\u0026rsquo;. However, OpenSSL actually just escapes unrecognized bytes as hexadecimal strings. Manual verification is required in such cases.\nUR2: The output of decoding detectors becomes unreliable due to the unrecognized character handling modes.\n\u0026#34;OpenSSL-SubjectOneline-2.5.4.3-BMPString\u0026#34;: { \u0026#34;parsing_failed\u0026#34;: [], \u0026#34;possible_replacement\u0026#34;: [], \u0026#34;replacement\u0026#34;: [], \u0026#34;possible_escaping\u0026#34;: [ \u0026#34;0001-108C79\u0026#34; ], \u0026#34;escaping\u0026#34;: [], \u0026#34;possible_truncation\u0026#34;: [], \u0026#34;truncation\u0026#34;: [], \u0026#34;possible_decodings\u0026#34;: [], \u0026#34;possible_decodings_ex\u0026#34;: [], \u0026#34;is_unidecoding\u0026#34;: false, \u0026#34;deduced_decoding\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;deduced_decoding_ex\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;deduced_decoding_include_ex\u0026#34;: \u0026#34;unknown\u0026#34; } Through manual inspection, you can approximate a field\u0026rsquo;s decoding method—for example, when \u0026lsquo;sU+0664ubject\u0026rsquo; undergoes UTF-16-BE encoding followed by decoding (with special character handling) to yield \u0026lsquo;\\x00s\\x06d\\x00u\\x00b\\x00j\\x00e\\x00c\\x00t\u0026rsquo;, this suggests an ASCII or ASCII-compatible decoder where U+0000 is escaped as\u0026rsquo;\\x00\u0026rsquo;. By analyzing such outputs for unicerts embedded with boundary characters (U+0080–U+00FF, U+FFFF–U+10FFFF), the exact decoding method can be determined.\nUR3: The decoding method for BMPString in java.security.cert remains unclear, with the only known detail being its full compatibility with ASCII. This represents the sole exception encountered during our decoding inference.\nOthers # Our decoding detectors need to determine the relationship between the embedded string in a field and its parsed value. This requires knowledge of how different TLS libraries parse specific field formats (e.g., prefixes like \u0026ldquo;CN=\u0026rdquo;, suffixes, etc.). Through extensive test certificate construction, we have precisely identified these parsing patterns, and these findings are directly implemented in the code. All results are shown in CertificateDecodingChecker/result.\n"},{"id":1,"href":"/docs/example/introduction/","title":"Introduction","section":"Unicert","content":" Introduction # The PKI system supports global use with X.509 certificates, integrating internationalized content like IDNs and multilingual text, referred to as Unicerts. This integration introduces complexity in Unicert issuance and usage. Past incidents showed that poor Unicode handling can cause security risks, including spoofing and remote code execution, yet threats specific to PKI and Unicerts remain underexplored. This paper presents the first large-scale study of Unicerts, examining both issuance and parsing compliance. By analyzing 34.8M Unicerts from CT logs and 9 mainstream TLS libraries, we found the PKI ecosystem struggles with adopting Unicode. On the issuing side, 373 CAs issued 249k (0.72%) non-compliant Unicerts due to weak validation on character ranges, normalization, and formatting, 65.3% of which were from publicly trusted CAs. These issues arise from overly complex standard requirements. On the parsing side, we found that libraries (e.g., GnuTLS and PyOpenSSL) exhibited issues in decoding and handling special characters, such as incompatible decoding and improper escaping, which could lead to incorrect entity extraction or subfield forgery. We further empirically identified three threat surfaces: user spoofing, CT monitor misleading, and traffic obfuscation. Finally, we analyzed root causes and proposed recommendations to enhance Unicert compliance in the global PKI ecosystem.\n"},{"id":2,"href":"/docs/introduction/","title":"Project Introduction","section":"Overview","content":" Introduction # The PKI system supports global use with X.509 certificates, integrating internationalized content like IDNs and multilingual text, referred to as Unicerts. This integration introduces complexity in Unicert issuance and usage. Past incidents showed that poor Unicode handling can cause security risks, including spoofing and remote code execution, yet threats specific to PKI and Unicerts remain underexplored. This paper presents the first large-scale study of Unicerts, examining both issuance and parsing compliance. By analyzing 34.8M Unicerts from CT logs and 9 mainstream TLS libraries, we found the PKI ecosystem struggles with adopting Unicode. On the issuing side, 373 CAs issued 249k (0.72%) non-compliant Unicerts due to weak validation on character ranges, normalization, and formatting, 65.3% of which were from publicly trusted CAs. These issues arise from overly complex standard requirements. On the parsing side, we found that libraries (e.g., GnuTLS and PyOpenSSL) exhibited issues in decoding and handling special characters, such as incompatible decoding and improper escaping, which could lead to incorrect entity extraction or subfield forgery. We further empirically identified three threat surfaces: user spoofing, CT monitor misleading, and traffic obfuscation. Finally, we analyzed root causes and proposed recommendations to enhance Unicert compliance in the global PKI ecosystem.\n"},{"id":3,"href":"/docs/introduction/method/1-unicert-compliance/","title":"Specification Analysis","section":"Method","content":" Specification Analysis # In this work, we explore the use of LLMs to interpret context-dependent rules and nested structural constraints in PKI systems and X.509 certificates. We acknowledge that these efforts are still at an early stage and are working to further refine them. We welcome feedback and suggestions from the community and provide a brief overview of our current approach below.\nSpecification Scope # The CA/Browser community enforces constraints primarily through the Baseline Requirements (BRs), and some CAs additionally check compliance with RFC 5280 before issuing certificates. However, certain domain-specific constraints not explicitly covered by RFC 5280 or the BRs also play an important role in PKI security. To address this, we considered all documents relevant to Unicert issuance, parsing, and validation. Ultimately, our analysis shows that RFC 5280 and the BRs are the most decisive, but our scope also included the PKIX specifications (RFC 3280, 5280), their updates (RFC 9549, 9598, 6818), reference documents (RFC 3490, 1034, 3454), related standards (RFC 6125, the IDNA suite), and the CA/B Forum Policy.\nAnalysis Steps # Extracting relevant standards and incorporating references to reflect their evolution and interdependencies. We filtered field-related sections from the desired documents using a set of specified keywords. We then refined the filtered sections by incorporating references from other specifications (e.g., domain name formats in RFC 1034) and replacing the outdated sections with updates from newer RFCs.\nImproving LLM comprehension of background knowledge. Inspired by a prior background-augmentation method, we incorporated the refined sections as background knowledge to enhance RFCGPT\u0026rsquo;s understanding of Unicert. Since CA/B BRs are not in RFCGPT’s pretraining data, we added their certificate profile content as supplemental knowledge. All knowledge was extracted as line-based text and placed in the background context fields of the prompt templates. For example, rules listed in tables were reformatted into comma-separated lines.\nPrompting the LLM to generate certificate field requirements. We used few-shot learning to prompt the LLM to extract two types of requirements for each certificate field: (1) valid encoding types and data structures, and (2) constraints on encoding and formatting. We excluded semantic constraints like field presence, absence, or criticality. Prompts included input–output examples to guide the LLM in generating requirements in a structured format (e.g., JSON), and directed it to reply No when standards lacked relevant details, avoiding fabrication.\n"},{"id":4,"href":"/docs/posts/checking-issuance-compliance/","title":"Checking Issuance Compliance","section":"Resources","content":"UniCheckSource Code\nUniCheck: A Zlint-based Certificate Compliance Checker # Overview # This repository contains UniCheck, a tool developed to investigate whether Unicode Certificates (Unicerts) comply with current standards.\nUniCheck is a customized version of the zlint framework, tailored specifically for our research purposes. It extends zlint\u0026rsquo;s functionality to provide in-depth compliance checks for Unicerts, focusing on aspects not explicitly covered by existing lints.\nSince this tool was designed for a specific academic study, it directly modifies the zlint source code within the vendor directory.\nImplementation Details # 1. New Lints for Unicert Compliance # We introduced a new directory at vendor/github.com/zmap/zlint/v3/lints/unicheck/ to house our custom lints. We also relocated existing lints relevant to checking encoding, format, attribute structure, and value normalization to this dedicated directory for better organization and a streamlined focus.\n2. Integration with the Lint Registry # To ensure our custom lints are recognized and executed by the zlint framework, we modified the project\u0026rsquo;s configuration to include our new directory in the lint registry. This involved adjusting the config/config.go and vendor/github.com/zmap/zlint/v3/zlint.go files.\nThe relevant changes ensure that all lints from our unicheck directory are included during the initialization of the zlint registry.\nvar sourceList lint.SourceList if err := sourceList.FromString(o.Config.ZlintIncludeSources); err != nil { log.Fatalf(\u0026#34;invalid includeSources: %v\\n\u0026#34;, err) } registry, err := lint.GlobalRegistry().Filter(lint.FilterOptions{ IncludeSources: sourceList,\t}) if err != nil { log.Fatalf(\u0026#34;lint registry filter failed to apply: %v\\n\u0026#34;, err) } o.GlobalZlintRegistry = registry log.Println(\u0026#34;[+] Included source names:\u0026#34;, registry.Sources()) log.Println(\u0026#34;[+] Included lints:\u0026#34;, len(registry.Names())) 3. Usage as a Library # Our application uses the modified zlint framework as a library to perform compliance checks on a single X.509 certificate object. The process involves three main steps:\nDecoding: The certificate\u0026rsquo;s PEM string is decoded into a DER block. Error handling is in place to catch any PEM parsing failures.\nParsing: The DER bytes are parsed to create an x509 certificate object. This step also includes error checks to handle invalid certificate structures.\nLint Execution: The zlint.LintCertificateEx function is called on the parsed x509 object, using our customized GlobalZlintRegistry, to execute all relevant lints. The results are then captured and returned in a structured format.\n// First, decode PEM string certDerBlock, _ := pem.Decode([]byte(pemStr)) if certDerBlock == nil { res := MyZlintRes{ Sha1: certSha1, Success: false, ErrorInfo: \u0026#34;Failed to parse PEM block containing the certificate\u0026#34;, } resStr, _ := json.Marshal(res) log.Println(\u0026#34;Failed to parse PEM block containing the certificate\u0026#34;) return string(resStr) + \u0026#34;\\n\u0026#34; } // Second, parse DER cert bytes and initialized an x509 object parsed, err := x509.ParseCertificate(certDerBlock.Bytes) if err != nil { log.Println(\u0026#34;Unable to parse certificate:\u0026#34;, err) res := MyZlintRes{ Sha1: certSha1, Success: false, ErrorInfo: fmt.Sprintf(\u0026#34;Unable to parse certificate: %s\\n\u0026#34;, err), } resStr, _ := json.Marshal(res) return string(resStr) + \u0026#34;\\n\u0026#34; } // Third, excecute zlint for one x509 object zlintResultSet := zlint.LintCertificateEx(parsed, c.GlobalZlintRegistry) res := MyZlintRes{ Sha1: certSha1, Success: true, ZlintRes: zlintResultSet, } resStr, _ := json.Marshal(res) ... "},{"id":5,"href":"/docs/introduction/method/2-tls-implementation-analysis/","title":"TLS Implementation Analysis","section":"Method","content":" TLS Implementation Analysis # Abstraction of Certificate Parsing Flow # "},{"id":6,"href":"/docs/introduction/method/","title":"Method","section":"Project Introduction","content":" Methodology Introduction # This study investigates whether the issuance and parsing of Unicert are compliant with current standards. We provide the method for analyzing Unicert issuance compliance and testing parsing anomalies in general-purpose TLS libraries.\n"},{"id":7,"href":"/docs/example/hidden/","title":"Hidden","section":"Unicert","content":" This page is hidden in menu # Quondam non pater est dignior ille Eurotas # Latent te facies # Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.\nPater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor Cum honorum Latona # O fallor in sustinui iussorum equidem. Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima iamdudum maius?\nreality(burnDocking(apache_nanometer), pad.property_data_programming.sectorBrowserPpga(dataMask, 37, recycleRup)); intellectualVaporwareUser += -5 * 4; traceroute_key_upnp /= lag_optical(android.smb(thyristorTftp)); surge_host_golden = mca_compact_device(dual_dpi_opengl, 33, commerce_add_ppc); if (lun_ipv) { verticalExtranet(1, thumbnail_ttl, 3); bar_graphics_jpeg(chipset - sector_xmp_beta); } Fronde cetera dextrae sequens pennis voce muneris # Acta cretus diem restet utque; move integer, oscula non inspirat, noctisque scelus! Nantemque in suas vobis quamvis, et labori!\nvar runtimeDiskCompiler = home - array_ad_software; if (internic \u0026gt; disk) { emoticonLockCron += 37 + bps - 4; wan_ansi_honeypot.cardGigaflops = artificialStorageCgi; simplex -= downloadAccess; } var volumeHardeningAndroid = pixel + tftp + onProcessorUnmount; sector(memory(firewire + interlaced, wired)); "},{"id":8,"href":"/docs/shortcodes/tabs/","title":"Tabs","section":"Shortcodes","content":" Tabs # Tabs let you organize content by context, for example installation instructions for each supported platform.\n{{\u0026lt; tabs \u0026#34;id\u0026#34; \u0026gt;}} {{% tab \u0026#34;MacOS\u0026#34; %}} # MacOS Content {{% /tab %}} {{% tab \u0026#34;Linux\u0026#34; %}} # Linux Content {{% /tab %}} {{% tab \u0026#34;Windows\u0026#34; %}} # Windows Content {{% /tab %}} {{\u0026lt; /tabs \u0026gt;}} Example # MacOS MacOS # This is tab MacOS content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nLinux Linux # This is tab Linux content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nWindows Windows # This is tab Windows content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nHints # Hint shortcode can be used as a hint/alert/notification block.\nSupport for markdown alerts # Note\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa\nTip\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa\nImportant\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa\nWarning\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa\nCaution\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa\nButtons # Buttons are styled links that can lead to local page or external link.\nExample # {{\u0026lt; button relref=\u0026#34;/\u0026#34; [class=\u0026#34;...\u0026#34;] \u0026gt;}}Get Home{{\u0026lt; /button \u0026gt;}} {{\u0026lt; button href=\u0026#34;https://github.com/alex-shpak/hugo-book\u0026#34; \u0026gt;}}Contribute{{\u0026lt; /button \u0026gt;}} Get Home Contribute Badges # TitleValue Hugo0.147.6 BuildPassing Coverage25% Issues120\nBadges can be used to annotate your pages with additional information or mark specific places in markdown content.\nExamples # Shortcode Output {{\u0026lt; badge style=\u0026quot;info\u0026quot; title=\u0026quot;hugo\u0026quot; value=\u0026quot;0.147.6\u0026quot; \u0026gt;}} Hugo0.147.6 {{\u0026lt; badge style=\u0026quot;success\u0026quot; title=\u0026quot;Build\u0026quot; value=\u0026quot;Passing\u0026quot; \u0026gt;}} BuildPassing {{\u0026lt; badge style=\u0026quot;warning\u0026quot; title=\u0026quot;Coverage\u0026quot; value=\u0026quot;25%\u0026quot; \u0026gt;}} Coverage25% {{\u0026lt; badge style=\u0026quot;danger\u0026quot; title=\u0026quot;Issues\u0026quot; value=\u0026quot;120\u0026quot; \u0026gt;}} Issues120 {{\u0026lt; badge style=\u0026quot;info\u0026quot; title=\u0026quot;Title\u0026quot; \u0026gt;}} Title {{\u0026lt; badge style=\u0026quot;info\u0026quot; value=\u0026quot;Value\u0026quot; \u0026gt;}} Value {{\u0026lt; badge title=\u0026quot;Default\u0026quot; \u0026gt;}} Default Use in links # A badge can be wrapped in markdown link producing following result: Hugo0.147.6\n[{{\u0026lt; badge title=\u0026#34;Hugo\u0026#34; value=\u0026#34;0.147.6\u0026#34; \u0026gt;}}](https://github.com/gohugoio/hugo/releases/tag/v0.147.6) "}]